{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "871b4abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import datetime as dt\n",
    "import random\n",
    "import psutil\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "import glob\n",
    "import pickle\n",
    "import torchvision\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import time\n",
    "\n",
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "def no_of_params(model):\n",
    "    sum_ = 0.\n",
    "    for key, value in model.state_dict().items():\n",
    "        sum_ += torch.prod(torch.tensor(value.shape))\n",
    "        #print(value, \"----------\", torch.prod(torch.tensor(value.shape)))\n",
    "    return int(sum_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5983328",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        list_IDs,\n",
    "    ):\n",
    "        self.list_IDs  = list_IDs\n",
    "        self.cache     = {}\n",
    "        self.input_dir = \"D:/Harsh Workspace/Software/GU/instrument_position_detection_using_ML/data/set_4/images/\"\n",
    "        self.label_dir = \"D:/Harsh Workspace/Software/GU/instrument_position_detection_using_ML/data/set_4/labels/\"\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.list_IDs)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        ID = self.list_IDs[index]\n",
    "        if ID in self.cache:\n",
    "            X = self.cache[ID]['X']\n",
    "            Y = self.cache[ID]['Y']\n",
    "        else:\n",
    "            X = torchvision.io.read_image(\n",
    "                self.input_dir + str(ID) + \".png \"\n",
    "            ).to(torch.float32)\n",
    "            X = X[1].unsqueeze(0)/256.\n",
    "            \n",
    "            with open(self.label_dir + str(ID), 'rb') as fb:\n",
    "                Y  = pickle.load(fb)\n",
    "                \n",
    "            #Y = [ (i + 3.)/6. for i in Y[0] ] + [i/3.14 for i in Y[1]]\n",
    "            #Y = [ i/3. for i in Y[0] ] + [i/3.14 for i in Y[1]]\n",
    "            \n",
    "            Y = Y[1][0]/3.1415926\n",
    "            Y = Y - 0.5\n",
    "            \n",
    "            Y = torch.tensor( Y, dtype=torch.float32 ).unsqueeze(0)\n",
    "            \n",
    "            if psutil.virtual_memory().percent < 50:\n",
    "                data = {\n",
    "                    'X' : X,\n",
    "                    'Y' : Y\n",
    "                }\n",
    "                self.cache[ID] = data\n",
    "        return X,Y\n",
    "    \n",
    "all_ids = [str(i) for i in  list(np.arange(0,10000,1))]\n",
    "#train_ids = all_ids[:8000]\n",
    "#val_ids   = all_ids[8000:]#1000]\n",
    "\n",
    "train_ids = all_ids[:800]\n",
    "val_ids   = all_ids[800:1000]#1000]\n",
    "\n",
    "params = {\n",
    "    'batch_size'  : 8,\n",
    "    'shuffle'     : True,\n",
    "    #'num_workers' : 2\n",
    "}\n",
    "training_set         = Dataset(train_ids)\n",
    "training_generator   = torch.utils.data.DataLoader(\n",
    "                            training_set,\n",
    "                            **params,\n",
    "                            pin_memory=True\n",
    "                        )\n",
    "validation_set       = Dataset(val_ids)\n",
    "validation_generator = torch.utils.data.DataLoader(\n",
    "                            validation_set,\n",
    "                            **params,\n",
    "                            pin_memory=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5105888c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss_fn\n",
    "):\n",
    "    running_loss = 0.\n",
    "    #loss_fn = nn.MSELoss()\n",
    "    #loss_fn = nn.L1Loss()\n",
    "    \n",
    "    model.train(True)\n",
    "    \n",
    "    for i,batch in enumerate(training_generator):\n",
    "        X = batch[0]\n",
    "        Y = batch[1]\n",
    "        output = model(batch[0])\n",
    "        loss = loss_fn(Y, output)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        del X,Y,output\n",
    "    \n",
    "    return running_loss/(i+1)\n",
    "\n",
    "def validate_one_epoch(\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss_fn\n",
    "):\n",
    "    running_loss = 0.\n",
    "    #loss_fn = nn.MSELoss()\n",
    "    #loss_fn = nn.L1Loss()\n",
    "    model.train(False)\n",
    "    model.eval()\n",
    "    \n",
    "    for i,batch in enumerate(validation_generator):\n",
    "        X = batch[0]\n",
    "        Y = batch[1]\n",
    "        output = model(batch[0])\n",
    "        loss = loss_fn(Y, output)\n",
    "        #optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        del X,Y,output\n",
    "    \n",
    "    return running_loss/(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d1bf843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74405"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1  = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=5, stride=1, padding=1)\n",
    "        self.bn1    = nn.BatchNorm2d(8)\n",
    "        self.conv2  = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=5, stride=1, padding=1)\n",
    "        self.bn2    = nn.BatchNorm2d(16)\n",
    "        self.pool   = nn.MaxPool2d(2,2)\n",
    "        self.conv4  = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=1)\n",
    "        self.bn4    = nn.BatchNorm2d(32)\n",
    "        self.conv5  = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=1)\n",
    "        self.bn5    = nn.BatchNorm2d(64)\n",
    "        self.fc1    = nn.Linear(64*10*10, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = torch.tanh(self.bn1(self.conv1(input)))      \n",
    "        output = torch.tanh(self.bn2(self.conv2(output)))     \n",
    "        output = self.pool(output)                        \n",
    "        output = torch.tanh(self.bn4(self.conv4(output)))     \n",
    "        output = torch.tanh(self.bn5(self.conv5(output))) \n",
    "        #print(output.shape)\n",
    "        output = output.view(-1, 64*10*10)\n",
    "        output = self.fc1(output)\n",
    "        output = torch.tanh(output)\n",
    "\n",
    "        return output\n",
    "model = Network()\n",
    "no_of_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb262a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-7\n",
    "wd = 1e-3\n",
    "model = Network()\n",
    "\n",
    "epochs = 300\n",
    "optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr           = lr,\n",
    "        weight_decay = wd,\n",
    "    )\n",
    "\n",
    "scheduler = lr_scheduler.CyclicLR(\n",
    "    optimizer,\n",
    "    base_lr=3e-8,\n",
    "    max_lr=3e-7,\n",
    "    cycle_momentum=False,\n",
    "    gamma=1,\n",
    "    step_size_up=10,\n",
    "    step_size_down =10,\n",
    "    mode='triangular2',\n",
    ")\n",
    "\n",
    "train_losses = []\n",
    "val_losses   = []\n",
    "lrs          = []\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "#loss_fn = nn.L1Loss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train_one_epoch(model,optimizer,loss_fn)\n",
    "    val_loss   = validate_one_epoch(model,optimizer,loss_fn)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    #optimizer.step()\n",
    "    lrs.append(scheduler.optimizer.param_groups[0]['lr'])\n",
    "    scheduler.step()\n",
    "    print(\"EPOCH: \",epoch + 1, \" Train loss: \", round(train_loss,4), \" Val loss: \",round(val_loss,4), \" LR: \",round(scheduler.optimizer.param_groups[0]['lr'],10))\n",
    "\n",
    "# txt = \"learning rate: \" + str(lr) +  \" weight decay: \" + str(wd)\n",
    "# plt.title(txt)\n",
    "# plt.plot(train_losses)\n",
    "# plt.plot(val_losses)\n",
    "# plt.show()\n",
    "\n",
    "# for batch in validation_generator:\n",
    "#     break\n",
    "# output = model(batch[0])\n",
    "# output\n",
    "# plt.title(txt)\n",
    "# plt.plot(output.detach().numpy()*3.1415926)\n",
    "# plt.plot(batch[1].detach().numpy()*3.1415926)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
